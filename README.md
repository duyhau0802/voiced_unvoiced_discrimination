# voiced_unvoiced_discrimination (VUD) project 
## this project's aim is to distinguish between voiced and unvoiced speech sounds 
Voiced sounds are produced with the vibration of the vocal cords, while unvoiced sounds are produced without the vibration of the vocal cords.
VUD is important for speech perception and production. It helps us to distinguish between different words and phrases, and to produce speech that is clear and understandable.
## Implementation steps
- Step 1: Read input data
- Step 2: Data processing: dividing frames, calculating ste, zcr
- Step 3: Find the threshold T_ste and T_zcr
- Step 4: Standardize the ste and zcr functions
- Step 5: Make a decision
- Step 6: Draw a graph
## Results of running the program
File studio_F1
![image](https://github.com/duyhau0802/voiced_unvoiced_discrimination/assets/114060333/9654e590-8780-4cc2-a048-1954fa780b6b)
File studio_M1
![image](https://github.com/duyhau0802/voiced_unvoiced_discrimination/assets/114060333/8b3e376d-7990-4cce-b8c9-777d07b4ee80)
File phone_F1
![image](https://github.com/duyhau0802/voiced_unvoiced_discrimination/assets/114060333/66e786ae-a0c9-4be7-bdcb-44efb196b240)
File phone_M1
![image](https://github.com/duyhau0802/voiced_unvoiced_discrimination/assets/114060333/21d22020-2bc9-486d-a43a-79ce253d6e01)
## You can read about the threshold finding algorithm and the decision making algorithm in the ppt file




